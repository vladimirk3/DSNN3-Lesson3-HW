{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Intro to NN 3 (hw)",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "h97RdWrNxjed"
      },
      "source": [
        "# Домашнее задание. Свёрточные сети\n",
        "\n",
        "Здесь вам предстоит построить и обучить свою первую свёрточную сеть для классификации изображений на данных CIFAR10. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj5T_3dxxjee"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8967u5Bzxjef"
      },
      "source": [
        "## Данные\n",
        "\n",
        "CIFAR10\n",
        "* 60000 RGB изображений размером 32x32x3\n",
        "* 10 классов: самолёты, собаки, рыбы и т.п.\n",
        "\n",
        "<img src=\"https://www.samyzaf.com/ML/cifar10/cifar1.jpg\" style=\"width:60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFMGMCFrxjef"
      },
      "source": [
        "Загрузите данные, разделите их на обучающую и тестовую выборки. Размер тестовой выборки должен быть $10^4$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf04QwsBxjef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9218720-3328-4979-db34-075dd7b78b1d"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)\n",
        "\n",
        "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
        "\n",
        "print (X_train.shape,y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(40000, 32, 32, 3) (40000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0PfsV5Ud-kz",
        "outputId": "f31c756c-bd1a-4b64-9cc7-2c763cd165f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = np.array(cifar10.load_data())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XS_kZF9xjeh"
      },
      "source": [
        "Прежде чем приступать к основной работе, стоит убедиться что загруженно именно то, что требовалось:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sih-A1Dxjeh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "ab185520-0ea6-46ea-ff86-55b396d31c33"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=[12,10])\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.xlabel(class_names[y_train[i, 0]])\n",
        "    plt.imshow(X_train[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 12 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iXiYWbdxjei"
      },
      "source": [
        "## Подготовка данных\n",
        "\n",
        "Сейчас каждый пиксель изображения закодирован тройкой чисел (RGB) __от 0 до 255__. Однако лучше себя показывает подход, где значения входов нейросети распределены недалеко от 0.\n",
        "\n",
        "Давайте приведём все данные в диапазон __`[0, 1]`__ — просто разделим на соответствующий коэффициент:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhIwnVXdxjei"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_val = X_val / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSRXEBo9xjej"
      },
      "source": [
        "Исполните код ниже для проверки, что все выполнено корректно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZQD2dTpxjej"
      },
      "source": [
        "assert np.shape(X_train) == (40000, 32, 32, 3), \"data shape should not change\"\n",
        "assert 0.9 <= max(map(np.max, (X_train, X_val, X_test))) <= 1.05\n",
        "assert 0.0 <= min(map(np.min, (X_train, X_val, X_test))) <= 0.1\n",
        "assert len(np.unique(X_test / 255.)) > 10, \"make sure you casted data to float type\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdztr8BHxjej"
      },
      "source": [
        "## Архитектура сети\n",
        "\n",
        "Для начала реализуйте простую нейросеть:\n",
        "1. принимает на вход картинки размера 32 x 32 x 3;\n",
        "2. вытягивает их в вектор (`keras.layers.Flatten`);\n",
        "3. пропускает через 1 или 2 полносвязных слоя;\n",
        "4. выходной слой отдает вероятности принадлежности к каждому из 10 классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5VwlwV8xjek"
      },
      "source": [
        "Создайте полносвязную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0B2-vnExjek"
      },
      "source": [
        "import keras\n",
        "from keras import layers as L\n",
        "from keras import backend as K"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub9pQE0Nxjek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdc813d-d5a5-4ac0-8f09-a91fd5c3d85d"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(32, activation=\"tanh\"),\n",
        "    #второй полносвяный слой\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=5,\n",
        "          validation_split=0.2) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0751 - accuracy: 0.2017 - val_loss: 1.9785 - val_accuracy: 0.2444\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.9697 - accuracy: 0.2689 - val_loss: 1.9362 - val_accuracy: 0.2889\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9376 - accuracy: 0.2828 - val_loss: 1.9472 - val_accuracy: 0.2627\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9093 - accuracy: 0.3048 - val_loss: 1.9180 - val_accuracy: 0.3059\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.8855 - accuracy: 0.3153 - val_loss: 1.8985 - val_accuracy: 0.3077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f962c7485d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg6VYd3qxjel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e80d8b2-b71c-4716-940f-2c82eadee3db"
      },
      "source": [
        "dummy_pred = model.predict(X_train[:20])\n",
        "assert dummy_pred.shape == (20, 10)\n",
        "assert np.allclose(dummy_pred.sum(-1), 1)\n",
        "print(\"Успех!\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Успех!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZkOyMr0AnGe",
        "outputId": "157d80aa-df02-4d6d-8e07-4a4b982d8d04"
      },
      "source": [
        "dummy_pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05988115, 0.14278276, 0.05188534, 0.1733999 , 0.02792975,\n",
              "        0.2623586 , 0.10120534, 0.073461  , 0.08039229, 0.02670387],\n",
              "       [0.06400817, 0.3659683 , 0.02720441, 0.07597712, 0.0165698 ,\n",
              "        0.06278055, 0.01969714, 0.02036593, 0.27250922, 0.07491939],\n",
              "       [0.07846899, 0.06742488, 0.08972885, 0.1640393 , 0.09787489,\n",
              "        0.23700993, 0.07489944, 0.06153897, 0.10785758, 0.0211572 ],\n",
              "       [0.02121609, 0.02627613, 0.10455379, 0.11494669, 0.17864706,\n",
              "        0.12429216, 0.25379062, 0.13836646, 0.00516246, 0.03274856],\n",
              "       [0.0350334 , 0.02353292, 0.20492537, 0.11386975, 0.21677755,\n",
              "        0.11287268, 0.17395304, 0.09037274, 0.01180695, 0.01685568],\n",
              "       [0.0917211 , 0.06184179, 0.12306271, 0.18302715, 0.09831504,\n",
              "        0.20159537, 0.07543962, 0.06443583, 0.0756075 , 0.02495388],\n",
              "       [0.05652283, 0.37395257, 0.04233207, 0.09071738, 0.02584298,\n",
              "        0.06342507, 0.02697505, 0.0279576 , 0.18180174, 0.11047275],\n",
              "       [0.17768729, 0.09308378, 0.08068869, 0.08000846, 0.07947431,\n",
              "        0.06036361, 0.02935111, 0.11790487, 0.11590879, 0.1655291 ],\n",
              "       [0.13058966, 0.10529201, 0.063413  , 0.07991978, 0.07426692,\n",
              "        0.06117524, 0.03216679, 0.16344567, 0.07930145, 0.21042944],\n",
              "       [0.05367184, 0.27207127, 0.00895123, 0.01726118, 0.00724484,\n",
              "        0.00457878, 0.00340876, 0.01288228, 0.16506542, 0.45486444],\n",
              "       [0.3217892 , 0.02309421, 0.04952481, 0.02626529, 0.03598851,\n",
              "        0.02949894, 0.00652046, 0.01939824, 0.46235666, 0.02556372],\n",
              "       [0.07465827, 0.2488513 , 0.0125838 , 0.01919134, 0.01000115,\n",
              "        0.00571569, 0.00350287, 0.0141805 , 0.23090558, 0.38040948],\n",
              "       [0.02673616, 0.01183362, 0.18293786, 0.10725956, 0.2277122 ,\n",
              "        0.11525042, 0.20799507, 0.10435329, 0.00519862, 0.01072326],\n",
              "       [0.2900715 , 0.04699391, 0.04031573, 0.02393005, 0.02364568,\n",
              "        0.01789166, 0.00446014, 0.01452699, 0.49076965, 0.04739469],\n",
              "       [0.17085005, 0.07766704, 0.01430831, 0.01348302, 0.0081276 ,\n",
              "        0.00738653, 0.0019403 , 0.00743504, 0.6404847 , 0.05831735],\n",
              "       [0.03141896, 0.01445181, 0.16068238, 0.09912945, 0.25414896,\n",
              "        0.15515529, 0.16438057, 0.09287348, 0.0183611 , 0.00939799],\n",
              "       [0.01911777, 0.01378432, 0.09264605, 0.11721042, 0.11817988,\n",
              "        0.25011292, 0.29206517, 0.08140168, 0.00920128, 0.0062805 ],\n",
              "       [0.3009916 , 0.0221062 , 0.10162684, 0.04306532, 0.08900269,\n",
              "        0.04967854, 0.01820518, 0.05496784, 0.28970504, 0.03065071],\n",
              "       [0.18018843, 0.04548753, 0.14575721, 0.12815939, 0.09934229,\n",
              "        0.14501904, 0.04982335, 0.0622431 , 0.11275615, 0.03122359],\n",
              "       [0.06013292, 0.03548936, 0.12936538, 0.18970343, 0.10402096,\n",
              "        0.23550825, 0.12133083, 0.07846922, 0.03029457, 0.01568507]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hDL04T96hyh"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGcAp1lexjel"
      },
      "source": [
        "## Обучение сети\n",
        "\n",
        "**Задание 1.1 (обязательно)** Будем минимизировать многоклассовую кроссэкнропию с помощью __sgd__. Вам нужно получить сеть, которая достигнет __не менее 45%__ __accuracy__ на тестовых данных.\n",
        "\n",
        "__Важно:__ поскольку в y_train лежат номера классов, Керасу нужно либо указать sparse функции потерь и метрики оценки качества классификации (`sparse_categorical_crossentropy` и `sparse_categorical_accuracy`), либо конвертировать метки в one-hot формат.\n",
        "\n",
        "### Полезные советы\n",
        "* `model.compile` позволяет указать, какие метрики вы хотите вычислять.\n",
        "* В `model.fit` можно передать валидационную выборку (`validation_data=[X_val, y_val]`), для отслеживания прогресса на ней. Также рекомендуем сохранять результаты в [tensorboard](https://keras.io/callbacks/#tensorboard) или [wandb](https://docs.wandb.ai/integrations/jupyter). **Важно: логи tensorboard не получится без боли посмотреть через colab.** Workaround: скачать логи и запустить tensorboard локально или помучаться [с этим](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab).\n",
        "* По умолчанию сеть учится 1 эпоху. Совсем не факт, что вам этого хватит. Число эпох можно настроить в методе `fit` (`epochs`).\n",
        "* Ещё у Кераса есть много [полезных callback-ов](https://keras.io/callbacks/), которые можно попробовать. Например, автоматическая остановка или подбор скорости обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iVWfkypxjel"
      },
      "source": [
        "#y_train, y_val = (tf.keras.utils.to_categorical(y) for y in (y_train, y_val))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGJFy50fyFV8"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from time import time"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5w_Zj5Sxjem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b0be9e-8863-4539-ca32-ab9b88686b2c"
      },
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    #второй полносвяный слой\n",
        "    #keras.layers.Dense(64, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='sample/', histogram_freq=1, write_graph=True, write_images=True)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32 , \n",
        "          epochs=30,\n",
        "          callbacks=[tensorboard_cbk],\n",
        "          validation_split=0.2) \n",
        "from sklearn.metrics import accuracy_score\n",
        "print (\"test accuracy: \", accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1000/1000 [==============================] - 5s 4ms/step - loss: 1.9235 - accuracy: 0.3124 - val_loss: 1.7939 - val_accuracy: 0.3699\n",
            "Epoch 2/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7572 - accuracy: 0.3828 - val_loss: 1.7346 - val_accuracy: 0.3902\n",
            "Epoch 3/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6790 - accuracy: 0.4103 - val_loss: 1.6820 - val_accuracy: 0.4006\n",
            "Epoch 4/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6280 - accuracy: 0.4278 - val_loss: 1.6135 - val_accuracy: 0.4320\n",
            "Epoch 5/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5852 - accuracy: 0.4438 - val_loss: 1.5874 - val_accuracy: 0.4453\n",
            "Epoch 6/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5489 - accuracy: 0.4584 - val_loss: 1.6047 - val_accuracy: 0.4310\n",
            "Epoch 7/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5215 - accuracy: 0.4690 - val_loss: 1.5741 - val_accuracy: 0.4416\n",
            "Epoch 8/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4947 - accuracy: 0.4800 - val_loss: 1.5712 - val_accuracy: 0.4490\n",
            "Epoch 9/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4694 - accuracy: 0.4882 - val_loss: 1.5427 - val_accuracy: 0.4527\n",
            "Epoch 10/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4478 - accuracy: 0.4910 - val_loss: 1.5108 - val_accuracy: 0.4649\n",
            "Epoch 11/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4307 - accuracy: 0.4993 - val_loss: 1.5301 - val_accuracy: 0.4602\n",
            "Epoch 12/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4101 - accuracy: 0.5072 - val_loss: 1.4953 - val_accuracy: 0.4699\n",
            "Epoch 13/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3915 - accuracy: 0.5142 - val_loss: 1.5075 - val_accuracy: 0.4661\n",
            "Epoch 14/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3734 - accuracy: 0.5187 - val_loss: 1.4907 - val_accuracy: 0.4787\n",
            "Epoch 15/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3543 - accuracy: 0.5248 - val_loss: 1.5235 - val_accuracy: 0.4639\n",
            "Epoch 16/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3420 - accuracy: 0.5329 - val_loss: 1.5042 - val_accuracy: 0.4678\n",
            "Epoch 17/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3325 - accuracy: 0.5368 - val_loss: 1.4796 - val_accuracy: 0.4789\n",
            "Epoch 18/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3140 - accuracy: 0.5438 - val_loss: 1.4637 - val_accuracy: 0.4837\n",
            "Epoch 19/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2983 - accuracy: 0.5474 - val_loss: 1.5044 - val_accuracy: 0.4769\n",
            "Epoch 20/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2891 - accuracy: 0.5482 - val_loss: 1.4510 - val_accuracy: 0.4929\n",
            "Epoch 21/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2745 - accuracy: 0.5586 - val_loss: 1.4828 - val_accuracy: 0.4801\n",
            "Epoch 22/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2624 - accuracy: 0.5603 - val_loss: 1.4304 - val_accuracy: 0.4934\n",
            "Epoch 23/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2479 - accuracy: 0.5639 - val_loss: 1.4304 - val_accuracy: 0.4945\n",
            "Epoch 24/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2380 - accuracy: 0.5681 - val_loss: 1.4437 - val_accuracy: 0.4965\n",
            "Epoch 25/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2263 - accuracy: 0.5708 - val_loss: 1.4306 - val_accuracy: 0.5016\n",
            "Epoch 26/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2127 - accuracy: 0.5775 - val_loss: 1.5063 - val_accuracy: 0.4795\n",
            "Epoch 27/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2036 - accuracy: 0.5792 - val_loss: 1.4359 - val_accuracy: 0.5000\n",
            "Epoch 28/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1899 - accuracy: 0.5828 - val_loss: 1.4329 - val_accuracy: 0.4961\n",
            "Epoch 29/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1796 - accuracy: 0.5871 - val_loss: 1.4374 - val_accuracy: 0.5011\n",
            "Epoch 30/30\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1683 - accuracy: 0.5928 - val_loss: 1.4226 - val_accuracy: 0.5054\n",
            "test accuracy:  0.5066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI1bqoNFll3M",
        "outputId": "d63f8d3a-a6f8-4de4-ef59-309c501241b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "keras.callbacks.History"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.callbacks.History"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bM8coUaxjem"
      },
      "source": [
        "\n",
        "\n",
        "#model.compile(# Your code here)\n",
        "#model.fit(# Your code here)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZODNxMaQxjem"
      },
      "source": [
        "А теперь можно проверить качество вашей сети, выполнив код ниже:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "14l7JHe_xjem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8dc5c28-ba7f-4b57-f6a2-240f8340c635"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "test_acc = accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1))\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "assert test_acc > 0.50, \"Not good enough. Back to the drawing board :)\"\n",
        "print(\" Not bad!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test_acc = 0.5066\n",
            " Not bad!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm_SvVrqxjen"
      },
      "source": [
        "## Карманная сверточная сеть\n",
        "\n",
        "**Задание 1.2 (обязательно)** Реализуйте небольшую свёрточную сеть. Совсем небольшую:\n",
        "1. Входной слой\n",
        "2. Свёртка 3x3 с 10 фильтрами\n",
        "3. Нелинейность на ваш вкус\n",
        "4. Max-pooling 2x2\n",
        "5. Вытягиваем оставшееся в вектор (Flatten)\n",
        "6. Полносвязный слой на 100 нейронов\n",
        "7. Нелинейность на ваш вкус\n",
        "8. Выходной полносвязный слой с softmax\n",
        "\n",
        "Обучите её так же, как и предыдущую сеть. Если всё хорошо, у вас получится accuracy не меньше __50%__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bu_Sg2sCxjeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad4c94d-0c27-4021-ed54-b201e04668d9"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           activation='relu',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=20,\n",
        "          validation_split=0.2) \n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 10s 5ms/step - loss: 1.5502 - accuracy: 0.4414 - val_loss: 1.3452 - val_accuracy: 0.5244\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2658 - accuracy: 0.5527 - val_loss: 1.2732 - val_accuracy: 0.5450\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.1470 - accuracy: 0.5972 - val_loss: 1.2223 - val_accuracy: 0.5723\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.0615 - accuracy: 0.6248 - val_loss: 1.2291 - val_accuracy: 0.5631\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9856 - accuracy: 0.6515 - val_loss: 1.1751 - val_accuracy: 0.5841\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9212 - accuracy: 0.6748 - val_loss: 1.2124 - val_accuracy: 0.5801\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8599 - accuracy: 0.6967 - val_loss: 1.1834 - val_accuracy: 0.5969\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8083 - accuracy: 0.7148 - val_loss: 1.2008 - val_accuracy: 0.5932\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7539 - accuracy: 0.7353 - val_loss: 1.2140 - val_accuracy: 0.6005\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7020 - accuracy: 0.7538 - val_loss: 1.2550 - val_accuracy: 0.6019\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6561 - accuracy: 0.7715 - val_loss: 1.2454 - val_accuracy: 0.6054\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6134 - accuracy: 0.7843 - val_loss: 1.3098 - val_accuracy: 0.5922\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5677 - accuracy: 0.8006 - val_loss: 1.3584 - val_accuracy: 0.5945\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5316 - accuracy: 0.8127 - val_loss: 1.4384 - val_accuracy: 0.5836\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4882 - accuracy: 0.8306 - val_loss: 1.4929 - val_accuracy: 0.5841\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4491 - accuracy: 0.8436 - val_loss: 1.5469 - val_accuracy: 0.5911\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4150 - accuracy: 0.8557 - val_loss: 1.5452 - val_accuracy: 0.5890\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3837 - accuracy: 0.8672 - val_loss: 1.6804 - val_accuracy: 0.5879\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3506 - accuracy: 0.8781 - val_loss: 1.7147 - val_accuracy: 0.5776\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3188 - accuracy: 0.8908 - val_loss: 1.8153 - val_accuracy: 0.5867\n",
            "Test Accuracy:  0.588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37ZT8T4xjeo"
      },
      "source": [
        "Давайте посмотрим, смогла ли карманная сверточная сеть побить заданный порог по качеству:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAYvMxhTxjep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2537b946-3217-4c27-d120-79089e76dd9b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "test_acc = accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1))\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "assert test_acc > 0.50, \"Not good enough. Back to the drawing board :)\"\n",
        "print(\" Not bad!\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test_acc = 0.588\n",
            " Not bad!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "How0uQPzxjep"
      },
      "source": [
        "## Учимся учить\n",
        "\n",
        "А теперь научимся сравнивать кривые обучения моделей — зависимости значения accuracy от количества итераций. \n",
        "\n",
        "Вам потребуется реализовать _экспериментальный стенд_ — вспомогательный код, в который вы сможете подать несколько архитектур и методов обучения, чтобы он их обучил и вывел графики кривых обучения. Это можно сделать с помощью `keras.callbacks` — `TensorBoard` или `History`.\n",
        "\n",
        "Будьте морально готовы, что на обучение уйдёт _много времени_. Даже если вы ограничитесь 10 эпохами. Пока идёт обучение, вы можете переключиться на другие задания или заняться чем-нибудь приятным: поспать, например."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwmdGNIHxjep"
      },
      "source": [
        "**Задание 1.3 (опционально)** Попробуйте использовать различные методы оптимизации (sgd, momentum, adam) с параметрами по умолчанию. Какой из методов работает лучше?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsF9iIFGxjeq"
      },
      "source": [
        "Для удобства напишем класс Evaluator, который принимает в себя дикты виды {имя_оптимайзера: инстанс}, {имя модели: инстанс} и обучает всевозможные комбинации моделей с оптимайзерами при помощи метода fit (попутно записывая логи отдельно для каждой модели). Также пригодится метод evaluate для отображения итоговых скоров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBtU0x2X5gmG"
      },
      "source": [
        "Пользоваться классом не обязательно. По умолчанию класс использует tensorboard. Если вы выше использовали wandb -- советуем дописать callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6pRKzaKxjeq"
      },
      "source": [
        "class Evaluator(list):\n",
        "    def __init__(self, models, optimizers='adam', loss=keras.losses.categorical_crossentropy,\n",
        "                 metrics=[keras.metrics.categorical_accuracy]):\n",
        "        '''\n",
        "            models: dict {name: model}\n",
        "            optimizers: list of optimizers or just one optimizer\n",
        "        '''\n",
        "        if not isinstance(models, dict):\n",
        "            models = {'single_model': models}\n",
        "        if not isinstance(optimizers, dict):\n",
        "            optimizers = {str(optimizers.__class__): optimizers}\n",
        "        super().__init__([(model_name, keras.models.clone_model(model), optimizer_name, optimizer)\n",
        "                          for model_name, model in models.items()\n",
        "                          for optimizer_name, optimizer in optimizers.items()])\n",
        "        for _, model, _, optimizer in self:\n",
        "            model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "            \n",
        "    def fit(self, X, y, validation_data=(), max_epochs=100, verbose=0, callbacks=[], batch_size=32):\n",
        "        if not isinstance(callbacks, list):\n",
        "            callbacks = [callbacks]\n",
        "        for model_name, model, optimizer_name, optimizer in tqdm_notebook(self):\n",
        "            model.fit(X, y, validation_data=validation_data or None, epochs=max_epochs, verbose=verbose,\n",
        "                      batch_size=batch_size, callbacks=callbacks + [keras.callbacks.TensorBoard(\n",
        "                          log_dir='./logs/{}_{}'.format(model_name, optimizer_name))])\n",
        "            \n",
        "    def fit_generator(self, X, y, validation_data=(), max_epochs=100, verbose=1, callbacks=[], batch_size=32):\n",
        "        datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "        if not isinstance(callbacks, list):\n",
        "            callbacks = [callbacks]\n",
        "        for model_name, model, optimizer_name, optimizer in tqdm_notebook(self):\n",
        "            model.fit_generator(datagen.flow(X, y, batch_size=batch_size), epochs=max_epochs,\n",
        "                validation_data=validation_data or None, verbose=verbose,\n",
        "                callbacks=callbacks + [keras.callbacks.TensorBoard(\n",
        "                    log_dir='./logs/{}_{}'.format(model_name, optimizer_name))])\n",
        "        \n",
        "    def evaluate(self, X, y, metric):\n",
        "        for model_name, model, optimizer_name, _ in self:\n",
        "            print('Final score of {}_{} is {}'.format(model_name, optimizer_name,\n",
        "                  metric(y_test, model.predict_classes(X_test))))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpAWyAs7xjer"
      },
      "source": [
        "!rm -rf ./logs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X6IuIO-Nswh"
      },
      "source": [
        "optimizers = {\n",
        "    'sgd': 'SGD',\n",
        "    'adam': 'adam'\n",
        "}\n",
        "modelsgd = keras.models.Sequential([keras.Input(shape=(32, 32, 3)), keras.layers.Flatten()])\n",
        "modeladam = model = keras.models.Sequential([keras.Input(shape=(32, 32, 3)), keras.layers.Flatten()])\n",
        "models = {\n",
        "    'model_sgd': modelsgd,\n",
        "    'model_adam': modeladam\n",
        "}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sORtAnPykIm"
      },
      "source": [
        "Попробуем использовать различные алгоритмы оптимизации такие как RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLtng4Cwxjer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7218ade-b325-423b-b34f-296a6eb9202d"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    #второй полносвяный слой\n",
        "    #keras.layers.Dense(64, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "\n",
        "model.compile(optimizer='RMSprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='sample/', histogram_freq=1, write_graph=True, write_images=True)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32 , \n",
        "          epochs=25,\n",
        "          callbacks=[tensorboard_cbk],\n",
        "          validation_split=0.2) \n",
        "print (\"test accuracy: \", accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 2.0963 - accuracy: 0.2786 - val_loss: 1.8215 - val_accuracy: 0.3191\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7848 - accuracy: 0.3627 - val_loss: 1.7327 - val_accuracy: 0.3831\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7137 - accuracy: 0.3899 - val_loss: 1.6734 - val_accuracy: 0.4047\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6677 - accuracy: 0.4112 - val_loss: 1.7050 - val_accuracy: 0.3915\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6379 - accuracy: 0.4215 - val_loss: 1.6560 - val_accuracy: 0.4100\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6099 - accuracy: 0.4299 - val_loss: 1.6657 - val_accuracy: 0.4086\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5917 - accuracy: 0.4365 - val_loss: 1.6775 - val_accuracy: 0.4066\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5797 - accuracy: 0.4422 - val_loss: 1.5789 - val_accuracy: 0.4433\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5609 - accuracy: 0.4506 - val_loss: 1.6276 - val_accuracy: 0.4185\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5506 - accuracy: 0.4563 - val_loss: 1.5760 - val_accuracy: 0.4423\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5416 - accuracy: 0.4567 - val_loss: 1.6158 - val_accuracy: 0.4304\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5298 - accuracy: 0.4609 - val_loss: 1.5880 - val_accuracy: 0.4412\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5182 - accuracy: 0.4638 - val_loss: 1.6038 - val_accuracy: 0.4358\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5091 - accuracy: 0.4693 - val_loss: 1.5874 - val_accuracy: 0.4369\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5077 - accuracy: 0.4694 - val_loss: 1.6201 - val_accuracy: 0.4236\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4937 - accuracy: 0.4760 - val_loss: 1.5796 - val_accuracy: 0.4457\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4885 - accuracy: 0.4770 - val_loss: 1.6140 - val_accuracy: 0.4353\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4808 - accuracy: 0.4785 - val_loss: 1.6027 - val_accuracy: 0.4474\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4752 - accuracy: 0.4802 - val_loss: 1.6511 - val_accuracy: 0.4349\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4717 - accuracy: 0.4868 - val_loss: 1.5864 - val_accuracy: 0.4429\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4638 - accuracy: 0.4852 - val_loss: 1.6677 - val_accuracy: 0.4231\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4577 - accuracy: 0.4886 - val_loss: 1.6160 - val_accuracy: 0.4433\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4592 - accuracy: 0.4885 - val_loss: 1.6289 - val_accuracy: 0.4333\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4509 - accuracy: 0.4902 - val_loss: 1.6715 - val_accuracy: 0.4285\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4410 - accuracy: 0.4942 - val_loss: 1.5995 - val_accuracy: 0.4437\n",
            "test accuracy:  0.4543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo28ERBPoiL6",
        "outputId": "bc9b7ce6-0616-4879-d8cf-77f0637cae41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    #второй полносвяный слой\n",
        "    #keras.layers.Dense(64, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='sample/', histogram_freq=1, write_graph=True, write_images=True)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32 , \n",
        "          epochs=25,\n",
        "          callbacks=[tensorboard_cbk],\n",
        "          validation_split=0.2) \n",
        "print (\"test accuracy: \", accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.9538 - accuracy: 0.3046 - val_loss: 1.8334 - val_accuracy: 0.3372\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7712 - accuracy: 0.3690 - val_loss: 1.7398 - val_accuracy: 0.3741\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7080 - accuracy: 0.3892 - val_loss: 1.6813 - val_accuracy: 0.3884\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6637 - accuracy: 0.4094 - val_loss: 1.6934 - val_accuracy: 0.3935\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6308 - accuracy: 0.4225 - val_loss: 1.6487 - val_accuracy: 0.4059\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6142 - accuracy: 0.4290 - val_loss: 1.6615 - val_accuracy: 0.4150\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5922 - accuracy: 0.4342 - val_loss: 1.6252 - val_accuracy: 0.4256\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5721 - accuracy: 0.4411 - val_loss: 1.6299 - val_accuracy: 0.4182\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5525 - accuracy: 0.4488 - val_loss: 1.5844 - val_accuracy: 0.4367\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5423 - accuracy: 0.4519 - val_loss: 1.6145 - val_accuracy: 0.4239\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5269 - accuracy: 0.4597 - val_loss: 1.6290 - val_accuracy: 0.4130\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5200 - accuracy: 0.4604 - val_loss: 1.5805 - val_accuracy: 0.4268\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5086 - accuracy: 0.4629 - val_loss: 1.6592 - val_accuracy: 0.4112\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4961 - accuracy: 0.4663 - val_loss: 1.5939 - val_accuracy: 0.4405\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4954 - accuracy: 0.4686 - val_loss: 1.6000 - val_accuracy: 0.4347\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4832 - accuracy: 0.4716 - val_loss: 1.5480 - val_accuracy: 0.4494\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4729 - accuracy: 0.4761 - val_loss: 1.5471 - val_accuracy: 0.4581\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4625 - accuracy: 0.4787 - val_loss: 1.5935 - val_accuracy: 0.4319\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4617 - accuracy: 0.4794 - val_loss: 1.5571 - val_accuracy: 0.4495\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4534 - accuracy: 0.4830 - val_loss: 1.5954 - val_accuracy: 0.4290\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4482 - accuracy: 0.4835 - val_loss: 1.5735 - val_accuracy: 0.4462\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4382 - accuracy: 0.4889 - val_loss: 1.5933 - val_accuracy: 0.4406\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4345 - accuracy: 0.4895 - val_loss: 1.5756 - val_accuracy: 0.4433\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4285 - accuracy: 0.4928 - val_loss: 1.5881 - val_accuracy: 0.4392\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4237 - accuracy: 0.4950 - val_loss: 1.5743 - val_accuracy: 0.4465\n",
            "test accuracy:  0.4574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbhP0vhu09b6",
        "outputId": "6af52e78-00c5-4f05-e740-c7dcc2ca3fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    #второй полносвяный слой\n",
        "    #keras.layers.Dense(64, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "\n",
        "model.compile(optimizer='Adagrad',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='sample/', histogram_freq=1, write_graph=True, write_images=True)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32 , \n",
        "          epochs=25,\n",
        "          callbacks=[tensorboard_cbk],\n",
        "          validation_split=0.2) \n",
        "print (\"test accuracy: \", accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 5s 4ms/step - loss: 1.9978 - accuracy: 0.2912 - val_loss: 1.8931 - val_accuracy: 0.3402\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.8555 - accuracy: 0.3538 - val_loss: 1.8264 - val_accuracy: 0.3618\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.8064 - accuracy: 0.3741 - val_loss: 1.7960 - val_accuracy: 0.3716\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7731 - accuracy: 0.3882 - val_loss: 1.7751 - val_accuracy: 0.3801\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7475 - accuracy: 0.3989 - val_loss: 1.7603 - val_accuracy: 0.3809\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7261 - accuracy: 0.4055 - val_loss: 1.7349 - val_accuracy: 0.3971\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7091 - accuracy: 0.4124 - val_loss: 1.7305 - val_accuracy: 0.3950\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6933 - accuracy: 0.4193 - val_loss: 1.7216 - val_accuracy: 0.3969\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6797 - accuracy: 0.4237 - val_loss: 1.6994 - val_accuracy: 0.4105\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6680 - accuracy: 0.4272 - val_loss: 1.6908 - val_accuracy: 0.4103\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6564 - accuracy: 0.4316 - val_loss: 1.6863 - val_accuracy: 0.4117\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6457 - accuracy: 0.4372 - val_loss: 1.6765 - val_accuracy: 0.4124\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6371 - accuracy: 0.4388 - val_loss: 1.6688 - val_accuracy: 0.4173\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6283 - accuracy: 0.4441 - val_loss: 1.6636 - val_accuracy: 0.4184\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6199 - accuracy: 0.4463 - val_loss: 1.6567 - val_accuracy: 0.4219\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6125 - accuracy: 0.4496 - val_loss: 1.6531 - val_accuracy: 0.4225\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6054 - accuracy: 0.4511 - val_loss: 1.6476 - val_accuracy: 0.4255\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5990 - accuracy: 0.4536 - val_loss: 1.6390 - val_accuracy: 0.4288\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5923 - accuracy: 0.4548 - val_loss: 1.6340 - val_accuracy: 0.4329\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5861 - accuracy: 0.4597 - val_loss: 1.6269 - val_accuracy: 0.4347\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5808 - accuracy: 0.4610 - val_loss: 1.6300 - val_accuracy: 0.4315\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5752 - accuracy: 0.4647 - val_loss: 1.6191 - val_accuracy: 0.4379\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5701 - accuracy: 0.4667 - val_loss: 1.6223 - val_accuracy: 0.4327\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5658 - accuracy: 0.4661 - val_loss: 1.6125 - val_accuracy: 0.4371\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5609 - accuracy: 0.4698 - val_loss: 1.6126 - val_accuracy: 0.4369\n",
            "test accuracy:  0.4458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yXH1f8z3Ix",
        "outputId": "3b5406e9-573e-44bd-fa95-b424d1d39190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    #второй полносвяный слой\n",
        "    #keras.layers.Dense(64, activation=\"tanh\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),]\n",
        ")\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
        "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir='sample/', histogram_freq=1, write_graph=True, write_images=True)\n",
        "model.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32 , \n",
        "          epochs=25,\n",
        "          callbacks=[tensorboard_cbk],\n",
        "          validation_split=0.2) \n",
        "print (\"test accuracy: \", accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.9285 - accuracy: 0.3085 - val_loss: 1.8559 - val_accuracy: 0.3216\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7572 - accuracy: 0.3806 - val_loss: 1.7396 - val_accuracy: 0.3831\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6829 - accuracy: 0.4084 - val_loss: 1.6548 - val_accuracy: 0.4204\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6300 - accuracy: 0.4269 - val_loss: 1.6302 - val_accuracy: 0.4249\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5873 - accuracy: 0.4465 - val_loss: 1.6273 - val_accuracy: 0.4193\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5549 - accuracy: 0.4566 - val_loss: 1.5676 - val_accuracy: 0.4467\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5233 - accuracy: 0.4674 - val_loss: 1.5591 - val_accuracy: 0.4482\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4982 - accuracy: 0.4785 - val_loss: 1.5458 - val_accuracy: 0.4486\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4725 - accuracy: 0.4855 - val_loss: 1.5680 - val_accuracy: 0.4442\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4526 - accuracy: 0.4924 - val_loss: 1.5354 - val_accuracy: 0.4556\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4278 - accuracy: 0.5010 - val_loss: 1.5008 - val_accuracy: 0.4704\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4118 - accuracy: 0.5067 - val_loss: 1.5101 - val_accuracy: 0.4709\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3921 - accuracy: 0.5128 - val_loss: 1.4989 - val_accuracy: 0.4679\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3750 - accuracy: 0.5210 - val_loss: 1.4777 - val_accuracy: 0.4775\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3590 - accuracy: 0.5275 - val_loss: 1.4799 - val_accuracy: 0.4734\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3399 - accuracy: 0.5337 - val_loss: 1.5287 - val_accuracy: 0.4597\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3288 - accuracy: 0.5382 - val_loss: 1.4879 - val_accuracy: 0.4733\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3104 - accuracy: 0.5440 - val_loss: 1.4830 - val_accuracy: 0.4756\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2988 - accuracy: 0.5456 - val_loss: 1.4517 - val_accuracy: 0.4891\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2866 - accuracy: 0.5500 - val_loss: 1.4394 - val_accuracy: 0.4906\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2756 - accuracy: 0.5564 - val_loss: 1.4548 - val_accuracy: 0.4936\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2633 - accuracy: 0.5619 - val_loss: 1.4655 - val_accuracy: 0.4839\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2483 - accuracy: 0.5646 - val_loss: 1.4308 - val_accuracy: 0.4992\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2390 - accuracy: 0.5683 - val_loss: 1.4409 - val_accuracy: 0.4934\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2263 - accuracy: 0.5760 - val_loss: 1.4616 - val_accuracy: 0.4880\n",
            "test accuracy:  0.4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQJqV2vjxjes"
      },
      "source": [
        "evaluator = Evaluator(model, optimizers=optimizers)\n",
        "evaluator.fit(X_train, y_train_labels, validation_data=(X_val, y_val))\n",
        "evaluator.evaluate(X_test, y_test, accuracy_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFMVTSbtxjes"
      },
      "source": [
        "Прокомментируйте полученные результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFLMxug21Cg_"
      },
      "source": [
        "При тестировании оптимизаторов SGD (0.49), Adam(0.45), Adagrad (0.44), RMSprop(0.45) лучший результат показал SGD (градиентный спуск). воможно поигравшись с параметрами можно было улучшить показатели но пока это для меня за гранью возможного"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVkaJnLWxjet"
      },
      "source": [
        "**Задание 1.4 (опционально)** Добавьте нормализацию по батчу (`BatchNormalization`) между свёрткой и активацией. Попробуйте использовать несколько нормализаций — в свёрточных и полносвязных слоях."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppe0LGStxjet"
      },
      "source": [
        "Для удобства реализуем класс Models, который по сути будет являться списком моделей с двумя методами: add (добавить слой ко всем моделям) и add_create (создать новую модель на основе базовой с дополнительным слоем). Пользоваться им необязательно, но вдруг :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zX9hd6Kxjet"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class Models(OrderedDict):\n",
        "    def __init__(self, models):\n",
        "        if not isinstance(models, dict):\n",
        "            models = OrderedDict({'base_model': models})\n",
        "        super().__init__(models)\n",
        "        \n",
        "    def add(self, layer):\n",
        "        for name, model in self.items():\n",
        "            model.add(layer)\n",
        "            \n",
        "    def add_create(self, name, layer):\n",
        "        base_model = next(iter(self.items()))[1]\n",
        "        new_model = keras.models.clone_model(base_model)\n",
        "        new_model.add(layer)\n",
        "        self.update({name: new_model})\n",
        "        \n",
        "    def add_update(self, name, layer):\n",
        "        base_model = self[next(reversed(self))]\n",
        "        new_model = keras.models.clone_model(base_model)\n",
        "        new_model.add(layer)\n",
        "        self.update({name: new_model})\n",
        "\n",
        "# Example of usage \n",
        "# models = Models(keras.Sequential())\n",
        "# models.add(L.InputLayer(input_shape=(32, 32, 3)))\n",
        "# models.add(L.Convolution2D(filters=10, kernel_size=(3, 3)))\n",
        "# models.add(L.MaxPooling2D())\n",
        "# models.add_create('conv_batchnorm', L.BatchNormalization())\n",
        "# models.add(L.Activation('relu'))\n",
        "# ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUAshodn7udK"
      },
      "source": [
        "Без нормализации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EByjaW8k7qN1",
        "outputId": "8859b035-3139-43c1-c428-5bd74972d624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model0 = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Activation('relu'),        \n",
        "   \n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "   \n",
        "    keras.layers.Flatten(),\n",
        " \n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    keras.layers.Activation('relu'),])\n",
        "\n",
        "model0.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model0.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=20,\n",
        "          validation_split=0.2) \n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(model0.predict(X_test),axis=1)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7120 - accuracy: 0.4002 - val_loss: 1.5385 - val_accuracy: 0.4569\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.4280 - accuracy: 0.5010 - val_loss: 1.3772 - val_accuracy: 0.5241\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3184 - accuracy: 0.5431 - val_loss: 1.3426 - val_accuracy: 0.5325\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2459 - accuracy: 0.5687 - val_loss: 1.2903 - val_accuracy: 0.5529\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2013 - accuracy: 0.5816 - val_loss: 1.2981 - val_accuracy: 0.5444\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1651 - accuracy: 0.5937 - val_loss: 1.2569 - val_accuracy: 0.5642\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1386 - accuracy: 0.6052 - val_loss: 1.2313 - val_accuracy: 0.5760\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1127 - accuracy: 0.6148 - val_loss: 1.2382 - val_accuracy: 0.5729\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0871 - accuracy: 0.6230 - val_loss: 1.2282 - val_accuracy: 0.5721\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0719 - accuracy: 0.6281 - val_loss: 1.2089 - val_accuracy: 0.5831\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0550 - accuracy: 0.6360 - val_loss: 1.2010 - val_accuracy: 0.5847\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0425 - accuracy: 0.6378 - val_loss: 1.2335 - val_accuracy: 0.5714\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0256 - accuracy: 0.6469 - val_loss: 1.2767 - val_accuracy: 0.5611\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0151 - accuracy: 0.6466 - val_loss: 1.2244 - val_accuracy: 0.5754\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0012 - accuracy: 0.6516 - val_loss: 1.2080 - val_accuracy: 0.5867\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9887 - accuracy: 0.6589 - val_loss: 1.2453 - val_accuracy: 0.5726\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9828 - accuracy: 0.6604 - val_loss: 1.2272 - val_accuracy: 0.5780\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9708 - accuracy: 0.6622 - val_loss: 1.2136 - val_accuracy: 0.5847\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9568 - accuracy: 0.6689 - val_loss: 1.2256 - val_accuracy: 0.5774\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9542 - accuracy: 0.6703 - val_loss: 1.2116 - val_accuracy: 0.5841\n",
            "Test Accuracy:  0.5893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWu-qT302B62"
      },
      "source": [
        "Попробоуем добавить нормализацию в свертку:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORtpt21G31YV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcc7a6f-7ca5-4ca1-cbfb-42a67706b6c2"
      },
      "source": [
        "model1 = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),        \n",
        "   \n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "   \n",
        "    keras.layers.Flatten(),\n",
        " \n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    keras.layers.Activation('relu'),])\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model1.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=20,\n",
        "          validation_split=0.2) \n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(model1.predict(X_test),axis=1)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.6172 - accuracy: 0.4360 - val_loss: 1.5911 - val_accuracy: 0.4367\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3091 - accuracy: 0.5417 - val_loss: 1.3258 - val_accuracy: 0.5393\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2055 - accuracy: 0.5782 - val_loss: 1.3547 - val_accuracy: 0.5291\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1439 - accuracy: 0.6036 - val_loss: 1.2333 - val_accuracy: 0.5756\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0942 - accuracy: 0.6239 - val_loss: 1.2819 - val_accuracy: 0.5591\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0537 - accuracy: 0.6358 - val_loss: 1.4588 - val_accuracy: 0.5301\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0213 - accuracy: 0.6498 - val_loss: 1.2579 - val_accuracy: 0.5763\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9924 - accuracy: 0.6576 - val_loss: 1.2210 - val_accuracy: 0.5888\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9723 - accuracy: 0.6658 - val_loss: 1.8417 - val_accuracy: 0.4902\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9466 - accuracy: 0.6733 - val_loss: 1.1914 - val_accuracy: 0.5979\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9329 - accuracy: 0.6794 - val_loss: 1.2790 - val_accuracy: 0.5840\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9155 - accuracy: 0.6836 - val_loss: 1.4025 - val_accuracy: 0.5474\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9030 - accuracy: 0.6873 - val_loss: 1.3137 - val_accuracy: 0.5822\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8932 - accuracy: 0.6928 - val_loss: 1.2630 - val_accuracy: 0.5913\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8826 - accuracy: 0.6935 - val_loss: 1.2935 - val_accuracy: 0.5789\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8676 - accuracy: 0.7023 - val_loss: 1.3366 - val_accuracy: 0.5709\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8630 - accuracy: 0.7013 - val_loss: 1.3316 - val_accuracy: 0.5863\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8559 - accuracy: 0.7036 - val_loss: 1.3347 - val_accuracy: 0.5726\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8475 - accuracy: 0.7075 - val_loss: 1.3795 - val_accuracy: 0.5626\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8383 - accuracy: 0.7119 - val_loss: 1.3548 - val_accuracy: 0.5744\n",
            "Test Accuracy:  0.5744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmOgFA-P81JT"
      },
      "source": [
        "добавим нормализацию в полносвязный слой:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl41jeUt3-om",
        "outputId": "b30ef6f3-21d8-4cfe-81b9-b92d669bdc45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2 = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Activation('relu'),        \n",
        "   \n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "   \n",
        "    keras.layers.Flatten(),\n",
        " \n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model2.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=20,\n",
        "          validation_split=0.2) \n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(model2.predict(X_test),axis=1)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 3.8692 - accuracy: 0.1647 - val_loss: 3.6908 - val_accuracy: 0.1014\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3182 - accuracy: 0.0994 - val_loss: 2.3083 - val_accuracy: 0.0988\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3052 - accuracy: 0.1000 - val_loss: 2.3048 - val_accuracy: 0.1019\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3038 - accuracy: 0.1014 - val_loss: 2.3031 - val_accuracy: 0.1016\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3040 - accuracy: 0.0987 - val_loss: 2.3036 - val_accuracy: 0.1016\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3039 - accuracy: 0.1031 - val_loss: 2.3031 - val_accuracy: 0.0940\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3042 - accuracy: 0.0993 - val_loss: 2.3040 - val_accuracy: 0.0949\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3044 - accuracy: 0.0965 - val_loss: 2.3031 - val_accuracy: 0.1011\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3043 - accuracy: 0.0985 - val_loss: 2.3042 - val_accuracy: 0.1004\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3043 - accuracy: 0.0991 - val_loss: 2.3040 - val_accuracy: 0.0949\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3044 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1005\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3045 - accuracy: 0.1015 - val_loss: 2.3037 - val_accuracy: 0.1001\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3039 - accuracy: 0.1009 - val_loss: 2.3048 - val_accuracy: 0.0940\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3038 - accuracy: 0.1020 - val_loss: 2.3038 - val_accuracy: 0.1001\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3038 - accuracy: 0.0982 - val_loss: 2.3034 - val_accuracy: 0.1001\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3037 - accuracy: 0.0995 - val_loss: 2.3036 - val_accuracy: 0.1019\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3036 - accuracy: 0.0980 - val_loss: 2.3036 - val_accuracy: 0.1019\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3036 - accuracy: 0.0976 - val_loss: 2.3034 - val_accuracy: 0.1054\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3036 - accuracy: 0.0988 - val_loss: 2.3034 - val_accuracy: 0.1014\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3037 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.0949\n",
            "Test Accuracy:  0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxEpXbuQFZMT"
      },
      "source": [
        "Добавим нормализацию между слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwwV-n2M7_sG",
        "outputId": "f41429f5-d7e5-4ac5-eb23-0230ae49eadb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3 = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "    keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "    \n",
        "    keras.layers.BatchNormalization(),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),])\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "model3.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=20,\n",
        "          validation_split=0.2)\n",
        "from sklearn.metrics import accuracy_score \n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(model3.predict(X_test),axis=1)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.6626 - accuracy: 0.3920 - val_loss: 1.5548 - val_accuracy: 0.4363\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.3555 - accuracy: 0.5123 - val_loss: 1.3752 - val_accuracy: 0.5089\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 18s 18ms/step - loss: 1.2522 - accuracy: 0.5548 - val_loss: 1.4511 - val_accuracy: 0.4919\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1868 - accuracy: 0.5785 - val_loss: 1.3837 - val_accuracy: 0.5186\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.1395 - accuracy: 0.5965 - val_loss: 1.3388 - val_accuracy: 0.5331\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0984 - accuracy: 0.6136 - val_loss: 1.5660 - val_accuracy: 0.4895\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0661 - accuracy: 0.6222 - val_loss: 1.3142 - val_accuracy: 0.5490\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0308 - accuracy: 0.6355 - val_loss: 1.6439 - val_accuracy: 0.4716\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 1.0070 - accuracy: 0.6429 - val_loss: 1.3561 - val_accuracy: 0.5347\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9819 - accuracy: 0.6509 - val_loss: 1.3398 - val_accuracy: 0.5540\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9652 - accuracy: 0.6564 - val_loss: 1.4515 - val_accuracy: 0.5296\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9472 - accuracy: 0.6643 - val_loss: 1.5303 - val_accuracy: 0.5139\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9285 - accuracy: 0.6692 - val_loss: 1.3723 - val_accuracy: 0.5533\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9145 - accuracy: 0.6768 - val_loss: 1.5299 - val_accuracy: 0.5213\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9014 - accuracy: 0.6825 - val_loss: 1.3986 - val_accuracy: 0.5430\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8883 - accuracy: 0.6852 - val_loss: 1.4656 - val_accuracy: 0.5441\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8795 - accuracy: 0.6901 - val_loss: 1.5531 - val_accuracy: 0.5145\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8627 - accuracy: 0.6938 - val_loss: 1.4285 - val_accuracy: 0.5501\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8584 - accuracy: 0.6960 - val_loss: 1.4624 - val_accuracy: 0.5486\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8459 - accuracy: 0.6996 - val_loss: 1.4668 - val_accuracy: 0.5469\n",
            "Test Accuracy:  0.5522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUBUmZoB0Izj"
      },
      "source": [
        "- без нормализации 0.58\n",
        "- нормализация в свертке 0.57\n",
        "- нормализация в полносвязном слое 0.11\n",
        "- нормализация между слоями 0.55\n",
        "Как видим, для данной модели нормализация оказалась даже немного вредной, особенно в полносвязном слое. при более многослойной модели нормализация должна дать прирост в скорости и точности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBUuoOXf3yMx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Doml67xjev"
      },
      "source": [
        "**Задание 1.5 (опционально)** Посмотрите на batch_size (параметр model.fit) - при большем батче модель будет быстрее проходить эпохи, но с совсем огромным батчом вам потребуется больше эпох для сходимости (т.к. сеть делает меньше шагов за одну эпоху).\n",
        "Найдите такое значение, при котором модель быстрее достигает точности 55%. **Hint**: используйте early stopping callback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1GsMtyIxjew"
      },
      "source": [
        "**Задание 1.6 (опционально)** Попробуйте найти такую комбинацию метода обучения и нормализации, при которой сеть имеет наилучшую кривую обучения. Поясните, что вы понимаете под \"наилучшей\" кривой обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-unmmw3Txjey"
      },
      "source": [
        "## Свёрточная нейросеть здорового человека\n",
        "\n",
        "**Задание 1.7 (обязательно попытаться)** Наигравшись выше, обучим большую свёрточную сеть, которая даст на тестовой выборке __accuracy больше 80%__. В этом задании вам потребуется провести эксперименты, сравнив их между собой в конце. Возможно, может быть несколько проще, если писать выводы во время или сразу после каждого эксперимента, после чего сделать общие выводы.\n",
        "\n",
        "Рекомендуем начать с лучшей модели предыдущего задания и постепенно её улучшать. Вы можете использовать всё, что угодно: любые активации, сколь угодно большие свёрточные слои и глубокие сети. Единственное ограничение: __нельзя использовать предобученные сети и дополнительные данные__.\n",
        "\n",
        "### Полезные советы\n",
        "* Для начала, неплохо бы научить что-нибудь побольше, чем 10 фильтров 3x3.\n",
        "* __Главное правило: одно изменение на эксперимент__. Если у вас есть 2 идеи по улучшению сети, сначала попробуйте их независимо. Может оказаться, что одно из них дало __+10%__ точности а другое __-7%__. А вы так и будете думать, что сделали 2 полезных изменения которые в сумме дают __+3%__. Если какая-то идея не работает — даже если она вам нравится - опишите ее и выкидывайте из дальнейших экспериментов.\n",
        "* __Be careful or you will dropout__. Дропаут (`L.Dropout`) может позволить вам обучить в несколько раз бОльшую сеть без переобучения, выжав несколько процентов качества. Это круто, но не стоит сразу ставить dropout 50%. Во-первых, слишком сильный дропаут только ухудшит сеть (underfitting). Во-вторых, даже если дропаут улучшает качество, он замедляет обучение. Рекомендуем начинать с небольшого дропаута, быстро провести основные эксперименты, а потом жахнуть в 2 раза больше нейронов и дропаута ~~на ночь~~.\n",
        "* __Аугментация данных__. Если котика слегка повернуть и подрезать (простите), он всё равно останется котиком. А в керасе есть [удобный класс](https://keras.io/preprocessing/image/), который поставит подрезание котиков на поток. Ещё можно сделать этот трюк в тесте: вертим картинку 10 раз, предсказываем вероятности и усредняем. Только один совет: прежде, чем учить, посмотрите глазами на аугментированные картинки. Если вы сами не можете их различить, то и сеть не сможет.\n",
        "* __Don't just stack more layers__. Есть более эффективные способы организовать слои, чем простой Sequential. Вот пара идей: [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions](https://arxiv.org/abs/1608.06993). Только не копируйте архитектуру подчистую — вам скорее всего хватит меньшего размера.\n",
        "* __Долго != плохо__. Более глубокие архитектуры обычно требуют бОльше эпох до сходимости. Это значит, что в первые несколько эпох они могут быть хуже менее глубоких аналогов. Дайте им время, запаситесь чаем и обмажьтесь batch-norm-ом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJkfhCNZ2ZEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84aa5263-ccc5-4e29-b17a-df2a12dd29dc"
      },
      "source": [
        "modelx = keras.models.Sequential([\n",
        "    keras.Input(shape=(32, 32, 3)),\n",
        "\n",
        "    #1\n",
        "    keras.layers.Conv2D(filters=64,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                           input_shape=X_train.shape[1:]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=64,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "    \n",
        "    #2\n",
        "    keras.layers.Conv2D(filters=128,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=128,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "\n",
        "    \n",
        "\n",
        "    #3\n",
        "    keras.layers.Conv2D(filters=256,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=256,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    #keras.layers.Conv2D(filters=256,\n",
        "    #                       kernel_size=(3, 3),\n",
        "    #                       padding='same',\n",
        "    #                    ),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    #keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "\n",
        "    #keras.layers.Conv2D(filters=256,\n",
        "    #                       kernel_size=(3, 3),\n",
        "    #                       padding='same',\n",
        "    #                    ),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    #keras.layers.Activation('relu'),\n",
        "\n",
        "    #keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "\n",
        "    #4\n",
        "    keras.layers.Conv2D(filters=512,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=512,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=512,\n",
        "                           kernel_size=(3, 3),\n",
        "                           padding='same',\n",
        "                        ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
        "\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.Flatten(),\n",
        "    #первый полносвязный слой\n",
        "    keras.layers.Dense(2000),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(2000),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),])\n",
        "modelx.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "modelx.fit(X_train, \n",
        "          y_train_labels,\n",
        "          batch_size=32, \n",
        "          epochs=25,\n",
        "          validation_split=0.2) \n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Test Accuracy: ', accuracy_score(y_test, np.argmax(modelx.predict(X_test),axis=1)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1000/1000 [==============================] - 95s 52ms/step - loss: 2.5281 - accuracy: 0.1384 - val_loss: 2.1165 - val_accuracy: 0.1719\n",
            "Epoch 2/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 1.9948 - accuracy: 0.2225 - val_loss: 1.8206 - val_accuracy: 0.2899\n",
            "Epoch 3/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 1.7672 - accuracy: 0.2900 - val_loss: 1.8035 - val_accuracy: 0.3175\n",
            "Epoch 4/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 1.6944 - accuracy: 0.3363 - val_loss: 1.9208 - val_accuracy: 0.2984\n",
            "Epoch 5/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 1.5403 - accuracy: 0.4262 - val_loss: 1.6815 - val_accuracy: 0.4067\n",
            "Epoch 6/25\n",
            "1000/1000 [==============================] - 53s 53ms/step - loss: 1.4056 - accuracy: 0.5154 - val_loss: 1.2719 - val_accuracy: 0.5501\n",
            "Epoch 7/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 1.2991 - accuracy: 0.5638 - val_loss: 1.3823 - val_accuracy: 0.5530\n",
            "Epoch 8/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 1.2374 - accuracy: 0.5928 - val_loss: 1.1011 - val_accuracy: 0.6206\n",
            "Epoch 9/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 1.0878 - accuracy: 0.6408 - val_loss: 1.1641 - val_accuracy: 0.5846\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 1.1079 - accuracy: 0.6477 - val_loss: 1.1233 - val_accuracy: 0.6118\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 1.0239 - accuracy: 0.6792 - val_loss: 0.9255 - val_accuracy: 0.6948\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 0.8971 - accuracy: 0.7138 - val_loss: 0.7656 - val_accuracy: 0.7439\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.7203 - accuracy: 0.7705 - val_loss: 0.8044 - val_accuracy: 0.7411\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.6223 - accuracy: 0.7992 - val_loss: 0.7697 - val_accuracy: 0.7479\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.5609 - accuracy: 0.8221 - val_loss: 0.9241 - val_accuracy: 0.7154\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4953 - accuracy: 0.8432 - val_loss: 0.7583 - val_accuracy: 0.7621\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4487 - accuracy: 0.8579 - val_loss: 0.7734 - val_accuracy: 0.7711\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3969 - accuracy: 0.8743 - val_loss: 0.8412 - val_accuracy: 0.7617\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3497 - accuracy: 0.8905 - val_loss: 1.1067 - val_accuracy: 0.7420\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3160 - accuracy: 0.9027 - val_loss: 0.7645 - val_accuracy: 0.7971\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2743 - accuracy: 0.9165 - val_loss: 0.8258 - val_accuracy: 0.7935\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2531 - accuracy: 0.9243 - val_loss: 0.8691 - val_accuracy: 0.7886\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2170 - accuracy: 0.9345 - val_loss: 0.8918 - val_accuracy: 0.7781\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2028 - accuracy: 0.9406 - val_loss: 0.9448 - val_accuracy: 0.7871\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1926 - accuracy: 0.9443 - val_loss: 0.8883 - val_accuracy: 0.8026\n",
            "Test Accuracy:  0.8003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mm6fAOTxje1"
      },
      "source": [
        "Момент истины: проверьте, какого качества достигла ваша сеть."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgUcJYLzxje2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a9e567-2b41-43ca-d7a6-68d1dba1431c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "test_acc = accuracy_score(y_test, np.argmax(modelx.predict(X_test),axis=1))\n",
        "print(\"\\n Test_acc =\", test_acc)\n",
        "if test_acc > 0.8:\n",
        "    print(\"Это победа!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test_acc = 0.8003\n",
            "Это победа!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjZo-jifxje2"
      },
      "source": [
        "А теперь, опишите свои <s>ощущения</s> результаты от проведенных экспериментов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9AIzcovLuy-"
      },
      "source": [
        "1) стартовал с точности 0.55. \n",
        "2) пробовал увеличиь количество фильтров - результат стал лучше, но больше 100 не стал, так как прироста большого не увидел.\n",
        "3) пробовал увеличивать количество нейроном в полносвязном слое - результат улучшился но разница между точностью тренироваочной и валидационной выборки с самом начала была огромной в сторону тренировочной. это говорит о переобучении тренировочной выборки. Поэтому применил регуляризацию, а именно метод Droup out. увеличивал количество нейроно и смотре прирост точности, параллельно увеличивая значение параметра для dropout (процет выключаемых нейронов)\n",
        "4) добавлял слои последовательно. при определнном количестве (например в 3м слое добавил 3 слоя) результат ухудшался, поэотму оставил 2.\n",
        "5) поставил нормализацию для сверточных слоев.\n",
        "6) когда уперся в 75% пришлось обратиться к другим моделям. в качестве эталона выбрал vgg16 и попытался ее реализовать. приблизился вплотную к 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "t_pIaUdUxje2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}